# Flutter AI Tutor App ğŸ“

A smart educational Flutter application built with **Google Gemini**, **ElevenLabs Text-to-Speech**, and **On-Device Speech Recognition**. It generates practice questions, allows students to show their working (via typing or freestyle drawing), and provides a fully interactive voice-based AI Tutor to guide them through their mistakes.

---

## ğŸŒŸ Key Features

1. **AI Question Generation**: Automatically generates personalized questions based on subject, topic, and difficulty using Gemini.
2. **Interactive Voice Tutor**: A voice loop that allows users to speak to an AI tutor.
   - **STT**: On-device speech recognition via `speech_to_text`.
   - **Intelligence**: Direct conversation with Gemini (`gemini-2.0-flash`), which is given context about the current question and the student's working space.
   - **TTS**: High-quality voice responses generated by ElevenLabs via a local Node.js backend and played using `just_audio`.
3. **Versatile Working Space**: A dedicated area where students can either type their solutions or use the **Handwriting Canvas** to draw out equations and diagrams.
4. **Progress Tracking & Firebase**: Authenticates users and stores their attempts, scores, and progress in Firebase Firestore.

---

## ğŸ— System Architecture

- **Frontend**: Flutter (iOS, Android, Web). Handles UI, local speech recognition, drawing canvas, and makes direct API calls to Gemini.
- **Backend (Node.js)**: A lightweight Express server located in the `backend/` folder. It acts as a secure proxy to convert text into ElevenLabs MP3 audio via their SDK, avoiding exposing the ElevenLabs API key on the client side.

---

## âš™ï¸ Prerequisites

Before you begin, ensure you have the following installed:
- [Flutter SDK](https://docs.flutter.dev/get-started/install) (v3.10.0 or higher)
- [Node.js](https://nodejs.org/) (v16.0 or higher)
- A [Google Gemini API Key](https://aistudio.google.com/)
- An [ElevenLabs API Key & Voice ID](https://elevenlabs.io/)
- A configured Firebase project (ensure `google-services.json` / `GoogleService-Info.plist` are set up if building for mobile).

---

## ğŸš€ Setup Instructions

### 1. Flutter Project Setup
1. Clone the repository and navigate to the project directory:
   ```bash
   cd hackathonproject
   ```
2. Install Flutter dependencies:
   ```bash
   flutter pub get
   ```
3. Create a `.env` file in the root directory of the Flutter project (`hackathonproject/.env`):
   ```env
   # Used for generating questions
   GEMINI_API_KEY="your_gemini_api_key_here"
   
   # Used for the Voice Tutor (can be the same as above, or separate for quota management)
   GEMINI_TUTOR_API_KEY="your_gemini_api_key_here"
   
   # URL for the Node.js TTS backend 
   # Use http://10.0.2.2:3000 for Android Emulator
   # Use your local IP (e.g., http://192.168.1.5:3000) for physical devices
   VOICE_TUTOR_BACKEND_URL="http://10.0.2.2:3000"
   ```

### 2. Node.js Backend Setup (TTS)
1. Navigate to the backend directory:
   ```bash
   cd backend
   ```
2. Install NPM dependencies:
   ```bash
   npm install
   ```
3. Create a `.env` file inside the `backend` directory (`hackathonproject/backend/.env`):
   ```env
   # ElevenLabs Setup
   ELEVENLABS_API_KEY="your_elevenlabs_api_key_here"
   ELEVENLABS_VOICE_ID="your_preferred_voice_id_here"
   ELEVENLABS_MODEL_ID="eleven_turbo_v2"
   PORT=3000
   ```
   *(Note: Ensure your ElevenLabs API key has `text_to_speech` permissions enabled).*
4. Start the backend server:
   ```bash
   node server.js
   ```
   You should see: `âœ… Voice Tutor backend listening on http://localhost:3000`

### 3. Run the App
With the backend running in a separate terminal window, return to the root folder and run the Flutter app:
```bash
flutter run
```

---

## ğŸ“ Key File Structure

```text
hackathonproject/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.js                        # Node.js backend for ElevenLabs TTS
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ controller/
â”‚   â”‚   â””â”€â”€ voice_tutor_controller.dart  # Manages Mic, STT, Gemini chat, and TTS playback loop
â”‚   â”œâ”€â”€ screens/
â”‚   â”‚   â””â”€â”€ question_screen.dart         # Main UI for questions, workspace, and tutor
â”‚   â”œâ”€â”€ services (API call etc)/
â”‚   â”‚   â”œâ”€â”€ gemini_service.dart          # Generates questions via Gemini
â”‚   â”‚   â”œâ”€â”€ tutor_gemini_service.dart    # Manages AI Tutor persona and direct Gemini chat
â”‚   â”‚   â”œâ”€â”€ voice_tutor_service.dart     # Communicates with Node.js backend for TTS audio
â”‚   â”‚   â””â”€â”€ conversation_storage...      # Persists chat history locally
â”‚   â””â”€â”€ widgets/
â”‚       â”œâ”€â”€ voice_tutor_panel.dart       # UI for the microphone, transcript, and AI reply
â”‚       â””â”€â”€ drawing_canvas.dart          # Freestyle handwriting custom painter
â”œâ”€â”€ .env                                 # Flutter environment variables
â””â”€â”€ pubspec.yaml
```

---

## ğŸ›  Troubleshooting

- **"Sorry, I couldn't catch that" instantly when tapping the mic:**
  Ensure you have granted microphone permissions on your device/emulator. The app includes a small warmup delay to accommodate Android emulator speech services, but requires a functional microphone.
- **Tutor gives a text response, but no audio plays:**
  1. Check if the Node.js backend is running.
  2. Verify your `VOICE_TUTOR_BACKEND_URL` in the Flutter `.env` matches your testing environment (e.g., `10.0.2.2` for emulator vs. local IP for physical devices).
  3. Ensure your `ELEVENLABS_API_KEY` has the correct `text_to_speech` permissions.
- **Firebase Initialization Errors:**
  Ensure you have properly initialized Firebase for your specific platform using the `flutterfire cli`.
